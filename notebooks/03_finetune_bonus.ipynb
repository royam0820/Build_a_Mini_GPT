{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Fine-tune TinyGPT on Your Own Text\nMake it speak in your style (poems, stories, etc.).\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Bonus fine-tune notebook\n# Assumes `model`, `encode`, `decode`, `block_size`, and `text`, `stoi` from 02_tinyGPT have been run.\nimport torch, textwrap\nfrom tqdm.auto import tqdm\n\nstudent_text = \\\"\\\"\\\"\nOnce upon a time in Puteaux, a curious coder started a tiny GPT...\n\\\"\\\"\\\"\n\nrepeat = 50\nmix = text + \"\\n\\n\" + student_text*repeat\nmix_ids = torch.tensor([stoi.get(c, 0) for c in mix], dtype=torch.long)\n\nn2 = int(0.9*len(mix_ids)); train2, val2 = mix_ids[:n2], mix_ids[n2:]\ndef get_batch2(split):\n    src = train2 if split==\"train\" else val2\n    ix = torch.randint(len(src)-block_size-1, (64,))\n    x = torch.stack([src[i:i+block_size] for i in ix])\n    y = torch.stack([src[i+1:i+block_size+1] for i in ix])\n    return x.to(next(model.parameters()).device), y.to(next(model.parameters()).device)\n\nopt = torch.optim.AdamW(model.parameters(), lr=1e-4)\nfor step in range(600):\n    xb,yb = get_batch2(\"train\")\n    _,loss = model(xb,yb)\n    opt.zero_grad(set_to_none=True); loss.backward(); opt.step()\n\ndef sample_text(prompt=\"Once upon a time\", temperature=0.9, top_k=50):\n    start = encode(prompt).unsqueeze(0).to(next(model.parameters()).device)\n    out = model.generate(start, max_new_tokens=400, temperature=temperature, top_k=top_k)[0].tolist()\n    return decode(out)\n\nprint(textwrap.fill(sample_text(), width=90))\n",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}